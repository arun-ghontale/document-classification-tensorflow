{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arun\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import nltk, re, time\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##restrict the review lengths to a 100 words max\n",
    "df = pd.read_csv(\"Reviews.csv\")\n",
    "df = df[df['Score']!=3]\n",
    "df['len_words'] = df.Text.apply(lambda x: len(x.split()))\n",
    "df = df[df['len_words'] <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['Text', 'Score']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\arun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\arun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  sentiment\n",
       "0  i have bought several of the vitality canned d...      5          1\n",
       "1  product arrived labeled as jumbo salted peanut...      1          0\n",
       "2  this is a confection that has been around a fe...      4          1\n",
       "3  if you are looking for the secret ingredient i...      2          0\n",
       "4  great taffy at a great price  there was a wide...      5          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Convert the sentiment scores to 0 or a 1 and preprocess the text\n",
    "data['sentiment']=[1 if (x>3) else 0 for x in data['Score']]\n",
    "data['Text']= [x.lower() for x in data['Text']]\n",
    "data['Text'] = data['Text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))##remove the non-alphanumerics\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403797, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arun\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py:177: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "##tokenize the text and restrict the number of vocabulary words to a max of 10000 words and removes all characters from the\n",
    "##filters string\n",
    "tokenizer = Tokenizer(nb_words=10000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Text'].values)\n",
    "##padding the sequences to 100 words\n",
    "X = pad_sequences(X)\n",
    "Y = pd.get_dummies(data['sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((403797, 100), (403797, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class imbalance datapoints 85.2799797918261\n"
     ]
    }
   ],
   "source": [
    "vals = [1 if each > 3 else 0 for each in data['Score'].values]\n",
    "print(\"class imbalance datapoints\",100*sum(vals)/len(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323037, 100) (323037,)\n",
      "(80760, 100) (80760,)\n"
     ]
    }
   ],
   "source": [
    "###80-20 split on the dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,data.sentiment, test_size = 0.2, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    2,   13,  106,\n",
       "         293,    9,    1, 5344,  589,   99,   66,  212,    3,   13,  111,\n",
       "          28,   41,    6,   39,    9,   29,  172,    1,   35,  608,   51,\n",
       "          23,    4, 2801,   55,    4, 1346,  530,    3,    5,  526,   85,\n",
       "          12, 4693,    8, 1621,    3,  105, 7360,    7,   35,   85,   55,\n",
       "         161]),\n",
       " 'i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###You can clearly observe the left padding\n",
    "X[0],data['Text'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 161)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['than'],tokenizer.word_index['most']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_rnn(n_words, embed_size, current_batch, lstm_sizes, learning_rate):\n",
    "    '''Build the Recurrent Neural Network'''\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    \n",
    "    ###None, None indicates that you are about to recieve an unknown batch size and unknown sequence length\n",
    "    with tf.name_scope('inputs'):\n",
    "        inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "\n",
    "    with tf.name_scope('labels'):\n",
    "        labels = tf.placeholder(tf.int32, [None, None], name='labels')\n",
    "\n",
    "    ###The keep prob for dropout\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    \n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "        embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1)) ##-1 because you don't know the batch size\n",
    "        ##if multiple RNN layers are used try tf.Variable(tf.random_uniform((n_words, embed_size), -1)) instead\n",
    "        embed = tf.nn.embedding_lookup(embedding, inputs)\n",
    "        # batch_size_tf = length(embed)\n",
    "        multi_RNN = []\n",
    "        for each in lstm_sizes:\n",
    "            lstm = tf.contrib.rnn.LSTMCell(each)\n",
    "            ##For dropout you need to add another wrapper layer around normal LSTM\n",
    "            drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "            multi_RNN.append(drop)\n",
    "        cell = tf.contrib.rnn.MultiRNNCell(multi_RNN)\n",
    "\n",
    "    with tf.name_scope(\"RNN_init_state\"):\n",
    "        # Getting an initial state of all zeros\n",
    "        initial_state = cell.zero_state(current_batch, tf.float32)\n",
    "    \n",
    "    # Run the data through the RNN layers\n",
    "    with tf.name_scope(\"RNN_forward\"):\n",
    "        # Run the data through the RNN layers\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, embed, initial_state=initial_state)\n",
    "\n",
    "\n",
    "    # Make the predictions\n",
    "    with tf.name_scope('predictions'):\n",
    "    \n",
    "        # Create the fully connected layers by taking the last output from the LSTM outputs\n",
    "        predictions = tf.contrib.layers.fully_connected(outputs[:, -1],\n",
    "                                                  num_outputs = 2,\n",
    "                                                  activation_fn = None,\n",
    "                                                  weights_initializer = tf.truncated_normal_initializer(stddev=0.1))\n",
    "        ##for tensorboard\n",
    "        tf.summary.histogram('predictions', predictions)\n",
    "    # Calculate the cost\n",
    "    with tf.name_scope('cost'):\n",
    "        # # Calculate the cost\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=predictions))\n",
    "        ##for tensorboard\n",
    "        tf.summary.scalar('cost', cost)\n",
    "\n",
    "    # Train the model with back prop\n",
    "    with tf.name_scope('train'):    \n",
    "\n",
    "        # # Train the model\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(cost)\n",
    "\n",
    "    # Determine the accuracy\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "\n",
    "        # # Determine the accuracy\n",
    "        correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        ##for tensorboard\n",
    "        tf.summary.histogram('accuracy', accuracy)\n",
    "\n",
    "    # Merge all of the summaries\n",
    "    merged = tf.summary.merge_all()    \n",
    "\n",
    "    # Export the nodes \n",
    "    export_nodes = ['inputs', 'labels', 'keep_prob_', 'initial_state', 'states','accuracy',\n",
    "                    'predictions', 'cost', 'train_op', 'merged']\n",
    "    \n",
    "    local_dict = locals()\n",
    "    Graph_dict = {each:local_dict[each] for each in export_nodes}\n",
    "\n",
    "######Alternatively you can also do the below    \n",
    "#     Graph = namedtuple('Graph', export_nodes)\n",
    "#     local_dict = locals()\n",
    "#     Graph_dict = Graph(*[local_dict[each] for each in export_nodes])\n",
    "##############################################\n",
    "\n",
    "    return Graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'inputs/inputs:0' shape=(?, ?) dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_rnn(n_words = 10000, \n",
    "                  embed_size = 200,\n",
    "                  current_batch = 50,\n",
    "                  lstm_sizes= [256],\n",
    "                  learning_rate = 0.001\n",
    "                 )\n",
    "model['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(y, n_classes, batch_size):\n",
    "    y_temp = np.zeros((batch_size, n_classes))\n",
    "    for ind,every in enumerate(y):\n",
    "        y_temp[ind][every[0]] = 1\n",
    "    \n",
    "    return y_temp\n",
    "\n",
    "def get_batches(x, y, batch_size, n_classes):\n",
    "    '''Create the batches for the training and validation data'''\n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], convert_to_categorical(y[ii:ii+batch_size], n_classes=n_classes, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_vals = next(get_batches(X_train,Y_train[:,None],batch_size=20, n_classes = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 100), (20, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_vals[0].shape,batch_vals[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[0m 0s , 0% ,0.7346000075340271, accuracy_train : 44.0]\n",
      "[1m 19s , Test loss : 0.6014 , Test accuracy : 78.66]\n",
      "\n",
      "\n",
      "\n",
      "[2m 40s , 12% ,0.16760000586509705, accuracy_train : 92.0]\n",
      "[4m 0s , Test loss : 0.1817 , Test accuracy : 92.97]\n",
      "\n",
      "\n",
      "\n",
      "[5m 25s , 24% ,0.15289999544620514, accuracy_train : 94.0]\n",
      "[6m 45s , Test loss : 0.1424 , Test accuracy : 94.53]\n",
      "\n",
      "\n",
      "\n",
      "[8m 7s , 37% ,0.051100000739097595, accuracy_train : 96.0]\n",
      "[9m 28s , Test loss : 0.1347 , Test accuracy : 94.67]\n",
      "\n",
      "\n",
      "\n",
      "[10m 50s , 49% ,0.225600004196167, accuracy_train : 94.0]\n",
      "[12m 11s , Test loss : 0.1177 , Test accuracy : 95.65]\n",
      "\n",
      "\n",
      "\n",
      "[13m 33s , 61% ,0.24410000443458557, accuracy_train : 92.0]\n",
      "[14m 54s , Test loss : 0.1136 , Test accuracy : 95.83]\n",
      "\n",
      "\n",
      "\n",
      "[16m 17s , 74% ,0.039400000125169754, accuracy_train : 100.0]\n",
      "[17m 39s , Test loss : 0.1091 , Test accuracy : 95.93]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "EPOCH : 1\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[18m 17s , 0% ,0.05009999871253967, accuracy_train : 98.0]\n",
      "[19m 38s , Test loss : 0.1015 , Test accuracy : 96.28]\n",
      "\n",
      "\n",
      "\n",
      "[21m 1s , 12% ,0.1039000004529953, accuracy_train : 96.0]\n",
      "[22m 22s , Test loss : 0.098 , Test accuracy : 96.39999999999999]\n",
      "\n",
      "\n",
      "\n",
      "[23m 44s , 24% ,0.06750000268220901, accuracy_train : 98.0]\n",
      "[25m 6s , Test loss : 0.0975 , Test accuracy : 96.52]\n",
      "\n",
      "\n",
      "\n",
      "[26m 31s , 37% ,0.007400000002235174, accuracy_train : 100.0]\n",
      "[27m 54s , Test loss : 0.1002 , Test accuracy : 96.49]\n",
      "\n",
      "\n",
      "\n",
      "[29m 20s , 49% ,0.20350000262260437, accuracy_train : 94.0]\n",
      "[30m 41s , Test loss : 0.0923 , Test accuracy : 96.69]\n",
      "\n",
      "\n",
      "\n",
      "[32m 6s , 61% ,0.14339999854564667, accuracy_train : 94.0]\n",
      "[33m 27s , Test loss : 0.0928 , Test accuracy : 96.64]\n",
      "\n",
      "\n",
      "\n",
      "[34m 50s , 74% ,0.034699998795986176, accuracy_train : 100.0]\n",
      "[36m 11s , Test loss : 0.0897 , Test accuracy : 96.82]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "epochs = 2\n",
    "loss_train,acc_train = ([],[])\n",
    "dataset_size = X.shape[0]\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    ##initalize all the tf global variables\n",
    "    sess.run(init)\n",
    "    since = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"EPOCH : {epoch}\")\n",
    "        print(\"-\"*200)\n",
    "        for ind_tr,(x_,y_) in enumerate(get_batches(X_train,Y_train[:,None],batch_size=batch_size, n_classes= 2)):\n",
    "            loss_val,acc_val,_ = sess.run([model['cost'],model['accuracy'],model['train_op']], feed_dict={model['inputs']: x_,\n",
    "                                                         model['labels']: y_,model['keep_prob_']: 0.5})\n",
    "            loss_train.append(loss_val)\n",
    "            acc_train.append(acc_val)\n",
    "            \n",
    "            if ind_tr%1000 == 0:\n",
    "                print(f\"[{time_since(since)} , {int(ind_tr*batch_size*100/dataset_size)}% ,{round(loss_val,4)}, accuracy_train : {round(acc_val*100,2)}]\")\n",
    "                loss_test,acc_test = ([],[])\n",
    "                for ind_te,(x_te,y_te) in enumerate(get_batches(X_test,Y_test[:,None],batch_size=batch_size, n_classes = 2)):\n",
    "                    loss_te,acc_te = sess.run([model['cost'],model['accuracy']], feed_dict={model['inputs']: x_te,\n",
    "                                                             model['labels']: y_te,model['keep_prob_']: 1})\n",
    "                    loss_test.append(loss_te)\n",
    "                    acc_test.append(acc_te)\n",
    "                print(f\"[{time_since(since)} , Test loss : {round(sum(loss_test)/len(loss_test),4)} , Test accuracy : {100*round(sum(acc_test)/len(acc_test),4)}]\")\n",
    "                print(\"\\n\\n\")\n",
    "                checkpoint = rf\".\\model_save\\sentiment_{epoch}_{ind_tr}.ckpt\"\n",
    "                saver.save(sess, checkpoint)\n",
    "        print(\"-\"*200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.66118528e-04 2.24816980e-05 1.01016781e-05 4.51556975e-04\n",
      " 7.44491590e-04 1.82171086e-01 8.16434164e-01] 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_output(query_vec, model, sess_test):\n",
    "    #     for _, x in enumerate(get_test_batches(x_test, batch_size), 1):\n",
    "    test_state = sess_test.run(model['initial_state'])\n",
    "    feed = {model['inputs']: x_query,\n",
    "            model['keep_prob_']: 1,\n",
    "            model['initial_state']: test_state}\n",
    "    predictions = sess_test.run(model['predictions'], feed_dict=feed)\n",
    "    return softmax(predictions[0])\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "scores = [3.0, 1.0, 0.2, 4.0,4.5, 10.0, 11.5]\n",
    "print(softmax(scores),sum(softmax(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##testing\n",
    "checkpoint = r\".\\model_save\\sentiment_1_6000.ckpt\"\n",
    "sentence = 'this is a bad product'\n",
    "x_query = np.array(tokenizer.texts_to_sequences([sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\model_save\\sentiment_1_6000.ckpt\n",
      "probabilities : [0.9942009  0.00579904]\n"
     ]
    }
   ],
   "source": [
    "model_test = build_rnn(n_words = 10000, \n",
    "                  embed_size = 200,\n",
    "                  current_batch = 1,\n",
    "                  lstm_sizes = [256],\n",
    "                  learning_rate = 0.001)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess_test:\n",
    "    sess_test.run(init)\n",
    "    # Load the model\n",
    "#     saver = tf.train.import_meta_graph(checkpoint+\".meta\")\n",
    "    saver.restore(sess_test, checkpoint)\n",
    "#     saver.restore(sess, checkpoint)\n",
    "#     print(predict_output(x_query, model, sess_test))\n",
    "    print(f\"probabilities : {predict_output(x_query, model_test, sess_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
